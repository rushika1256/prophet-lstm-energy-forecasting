{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":13545611,"datasetId":8602599,"databundleVersionId":14271435}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-11T17:38:15.059645Z","iopub.execute_input":"2026-01-11T17:38:15.059961Z","iopub.status.idle":"2026-01-11T17:38:17.280187Z","shell.execute_reply.started":"2026-01-11T17:38:15.059931Z","shell.execute_reply":"2026-01-11T17:38:17.278905Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"greninja2006/boujdour\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T17:41:06.806306Z","iopub.execute_input":"2026-01-11T17:41:06.807061Z","iopub.status.idle":"2026-01-11T17:41:18.218737Z","shell.execute_reply.started":"2026-01-11T17:41:06.807031Z","shell.execute_reply":"2026-01-11T17:41:18.217781Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/boujdour\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/boujdour/Boujdour 10T.csv', sep=\";\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T17:41:19.813790Z","iopub.execute_input":"2026-01-11T17:41:19.814068Z","iopub.status.idle":"2026-01-11T17:41:19.938744Z","shell.execute_reply.started":"2026-01-11T17:41:19.814042Z","shell.execute_reply":"2026-01-11T17:41:19.937888Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"           DateTime  zone1  zone2  zone3\n0  14/09/2022 17:10  59,81  14,88  60,77\n1  14/09/2022 17:20  59,68  15,08  60,52\n2  14/09/2022 17:30  60,45  15,25  60,63\n3  14/09/2022 17:40  59,72  15,15  59,29\n4  14/09/2022 17:50  60,75  15,60  60,43","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DateTime</th>\n      <th>zone1</th>\n      <th>zone2</th>\n      <th>zone3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14/09/2022 17:10</td>\n      <td>59,81</td>\n      <td>14,88</td>\n      <td>60,77</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14/09/2022 17:20</td>\n      <td>59,68</td>\n      <td>15,08</td>\n      <td>60,52</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14/09/2022 17:30</td>\n      <td>60,45</td>\n      <td>15,25</td>\n      <td>60,63</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14/09/2022 17:40</td>\n      <td>59,72</td>\n      <td>15,15</td>\n      <td>59,29</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14/09/2022 17:50</td>\n      <td>60,75</td>\n      <td>15,60</td>\n      <td>60,43</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"for col in df.columns[1:]:\n  df[col]=df[col].str.replace(\",\",\".\",regex=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T17:41:21.417269Z","iopub.execute_input":"2026-01-11T17:41:21.417984Z","iopub.status.idle":"2026-01-11T17:41:21.494563Z","shell.execute_reply.started":"2026-01-11T17:41:21.417957Z","shell.execute_reply":"2026-01-11T17:41:21.493933Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"for col in df.columns[1:]:\n  df[col]=df[col].astype(float)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T17:41:21.722055Z","iopub.execute_input":"2026-01-11T17:41:21.722526Z","iopub.status.idle":"2026-01-11T17:41:21.759044Z","shell.execute_reply.started":"2026-01-11T17:41:21.722503Z","shell.execute_reply":"2026-01-11T17:41:21.758503Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Ensure 'DateTime' is datetime type\ndf['DateTime'] = pd.to_datetime(df['DateTime'], dayfirst=True, errors='coerce')\n\n# Set DateTime as index\ndf = df.set_index('DateTime')\n\n# Sort by datetime just in case\ndf = df.sort_index()\n\n# Now resampling works\ndata_hourly = df.resample('1h').sum()\ndata_hourly_mean = df.resample('1h').mean()\ndata_daily_mean = data_hourly_mean.resample('1D').mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T17:41:36.170860Z","iopub.execute_input":"2026-01-11T17:41:36.171322Z","iopub.status.idle":"2026-01-11T17:41:36.421126Z","shell.execute_reply.started":"2026-01-11T17:41:36.171296Z","shell.execute_reply":"2026-01-11T17:41:36.420554Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!pip install optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T17:42:02.491306Z","iopub.execute_input":"2026-01-11T17:42:02.491862Z","iopub.status.idle":"2026-01-11T17:42:06.655182Z","shell.execute_reply.started":"2026-01-11T17:42:02.491834Z","shell.execute_reply":"2026-01-11T17:42:06.654221Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.5.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.17.1)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.10.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.3)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\nRequirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2.4.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna) (2024.2.0)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"pip install lightgbm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T17:42:06.656657Z","iopub.execute_input":"2026-01-11T17:42:06.656892Z","iopub.status.idle":"2026-01-11T17:42:09.766037Z","shell.execute_reply.started":"2026-01-11T17:42:06.656867Z","shell.execute_reply":"2026-01-11T17:42:09.765090Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.6.0)\nRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->lightgbm) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->lightgbm) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->lightgbm) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.0->lightgbm) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.0->lightgbm) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.0->lightgbm) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T17:42:11.379479Z","iopub.execute_input":"2026-01-11T17:42:11.380154Z","iopub.status.idle":"2026-01-11T17:42:15.567437Z","shell.execute_reply.started":"2026-01-11T17:42:11.380120Z","shell.execute_reply":"2026-01-11T17:42:15.566740Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\nCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.15.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\nRequirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.2.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\nDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-5.29.5\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install prophet lightgbm optuna tensorflow -q\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T17:42:24.168031Z","iopub.execute_input":"2026-01-11T17:42:24.168577Z","iopub.status.idle":"2026-01-11T17:42:27.581477Z","shell.execute_reply.started":"2026-01-11T17:42:24.168547Z","shell.execute_reply":"2026-01-11T17:42:27.580708Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# ================================================================\n# üìò Robust Hybrid Feature Engineering Pipeline\n# Prophet (Daily) + LSTM (Hourly) + Symbolic & Programmatic Features\n# ================================================================\n\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\n\n# ================================================================\n# 1Ô∏è‚É£ LOAD AND PREPARE DATA\n# ================================================================\n# Assume you already have:\n#  üîπ data ‚Üí original 10-min resolution dataframe\n#  üîπ data_hourly_mean ‚Üí hourly mean dataframe (aggregated from data)\n# Example: data_hourly_mean = data.resample('H').mean()\n\ndf_hourly = data_hourly_mean.copy()\ndf_hourly.index.name = \"DateTime\"\n\nprint(f\"Raw hourly data shape: {df_hourly.shape}\")\nprint(df_hourly.head())\n\n# ================================================================\n# 2Ô∏è‚É£ FEATURE ENGINEERING UTILITIES\n# ================================================================\n\ndef add_time_features(df):\n    \"\"\"Add calendar and cyclical time features.\"\"\"\n    df = df.copy()\n    df[\"hour\"] = df.index.hour\n    df[\"dayofweek\"] = df.index.dayofweek\n    df[\"month\"] = df.index.month\n    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5,6]).astype(int)\n    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n    return df\n\ndef add_lag_and_rolling(df, zones, lags=[1,3,6,12,24], rolls=[3,6,12,24]):\n    \"\"\"Add lag and rolling statistical features.\"\"\"\n    df = df.copy()\n    for z in zones:\n        for l in lags:\n            df[f\"{z}_lag_{l}\"] = df[z].shift(l)\n        for w in rolls:\n            df[f\"{z}_roll_mean_{w}\"] = df[z].rolling(window=w, min_periods=1).mean()\n            df[f\"{z}_roll_std_{w}\"] = df[z].rolling(window=w, min_periods=1).std().fillna(0)\n    return df\n\ndef add_derivatives(df, zones):\n    \"\"\"Add first/second derivatives and percentage change.\"\"\"\n    df = df.copy()\n    for z in zones:\n        df[f\"{z}_diff_1\"] = df[z].diff(1)\n        df[f\"{z}_diff_2\"] = df[z].diff(2)\n        df[f\"{z}_pct_change_1\"] = df[z].pct_change(1).replace([np.inf,-np.inf], np.nan).fillna(0)\n    return df\n\ndef add_fourier_terms(df, period_hours=24, K=3):\n    \"\"\"Add Fourier seasonal terms.\"\"\"\n    df = df.copy()\n    t = np.arange(len(df))\n    for k in range(1, K+1):\n        df[f\"fourier_sin_{k}\"] = np.sin(2*np.pi*k*t/period_hours)\n        df[f\"fourier_cos_{k}\"] = np.cos(2*np.pi*k*t/period_hours)\n    return df\n\ndef add_symbolic_like_features(df, zones):\n    \"\"\"Add interpretable symbolic-like nonlinear feature combinations.\"\"\"\n    df = df.copy()\n    for z in zones:\n        df[f\"{z}_sym_sinlag3_logroll6\"] = np.sin(df[f\"{z}_lag_3\"].fillna(0)) * np.log1p(df[f\"{z}_roll_mean_6\"].fillna(0))\n        df[f\"{z}_sym_lag1_over_lag24\"] = df[f\"{z}_lag_1\"] / (df[f\"{z}_lag_24\"].replace(0, np.nan))\n        df[f\"{z}_sym_prod_diff1_diff2\"] = df[f\"{z}_diff_1\"].fillna(0) * df[f\"{z}_diff_2\"].fillna(0)\n    return df\n\n# ================================================================\n# 3Ô∏è‚É£ APPLY PROGRAMMATIC + SYMBOLIC FEATURE ENGINEERING\n# ================================================================\nzones = [c for c in df_hourly.columns if c.startswith(\"zone\")]\ndf = df_hourly.copy()\ndf = add_time_features(df)\ndf = add_lag_and_rolling(df, zones)\ndf = add_derivatives(df, zones)\ndf = add_fourier_terms(df, period_hours=24, K=2)\ndf = add_symbolic_like_features(df, zones)\n\nprint(f\"‚úÖ After feature engineering: {df.shape[1]} columns\")\n\n# ================================================================\n# 4Ô∏è‚É£ PROPHET-DERIVED DAILY FEATURES (TREND + WEEKLY + YEARLY)\n# ================================================================\ntry:\n    from prophet import Prophet\n    prophet_available = True\nexcept:\n    try:\n        from fbprophet import Prophet\n        prophet_available = True\n    except:\n        prophet_available = False\n\nif prophet_available:\n    print(\"üß≠ Prophet detected ‚Äî extracting daily components...\")\n    daily = df_hourly.sum(axis=1).resample(\"D\").mean().reset_index()\n    daily.columns = [\"ds\", \"y\"]\n\n    m = Prophet(daily_seasonality=False, weekly_seasonality=True, yearly_seasonality=True)\n    m.fit(daily)\n    forecast = m.predict(m.make_future_dataframe(periods=0, freq=\"D\"))\n    comp = forecast[[\"ds\", \"trend\", \"weekly\", \"yearly\", \"yhat\"]].set_index(\"ds\")\n    comp[\"residual\"] = daily.set_index(\"ds\")[\"y\"] - comp[\"yhat\"]\n\n    # Upsample to hourly and align with df\n    comp_hourly = comp.reindex(pd.date_range(comp.index.min(), comp.index.max(), freq=\"H\")).ffill()\n    comp_hourly = comp_hourly.reindex(df.index, method=\"ffill\")\n    for col in comp_hourly.columns:\n        df[f\"prophet_{col}\"] = comp_hourly[col].values\nelse:\n    print(\"‚öôÔ∏è Prophet not available ‚Äî using STL decomposition fallback.\")\n    from statsmodels.tsa.seasonal import STL\n    daily = df_hourly.sum(axis=1).resample(\"D\").mean()\n    stl = STL(daily.interpolate(), period=7)\n    res = stl.fit()\n    comp = pd.DataFrame({\n        \"trend\": res.trend,\n        \"seasonal\": res.seasonal,\n        \"resid\": res.resid\n    })\n    comp_hourly = comp.reindex(pd.date_range(comp.index.min(), comp.index.max(), freq=\"H\")).ffill()\n    comp_hourly = comp_hourly.reindex(df.index, method=\"ffill\")\n    df[\"prophet_trend\"] = comp_hourly[\"trend\"].values\n    df[\"prophet_weekly\"] = comp_hourly[\"seasonal\"].values\n    df[\"prophet_residual\"] = comp_hourly[\"resid\"].values\n\n# ================================================================\n# 5Ô∏è‚É£ LSTM-DERIVED TEMPORAL EMBEDDINGS (OPTIONAL)\n# ================================================================\ntry:\n    import tensorflow as tf\n    from tensorflow.keras.models import Model\n    from tensorflow.keras.layers import LSTM, Dense, Input\n    from tensorflow.keras.callbacks import EarlyStopping\n    tf_available = True\nexcept:\n    tf_available = False\n\nif tf_available:\n    print(\"üî∂ TensorFlow available ‚Äî training LSTM encoder...\")\n    feature_cols = [c for c in df.columns if not c.startswith(\"zone\")] + [f\"{z}_lag_1\" for z in zones]\n    feature_cols = [c for c in feature_cols if c in df.columns]\n    df_train = df[feature_cols].fillna(method=\"ffill\").fillna(0)\n    seq_len = 24  # one-day lookback window\n\n    X, y = [], []\n    total = df_hourly.sum(axis=1)\n    for i in range(len(df_train)-seq_len):\n        X.append(df_train.iloc[i:i+seq_len].values)\n        y.append(total.iloc[i+seq_len])\n    X, y = np.array(X), np.array(y)\n\n    if len(X) > 0:\n        inp = Input(shape=(X.shape[1], X.shape[2]))\n        lstm_layer = LSTM(32, return_sequences=False, name=\"encoder_lstm\")(inp)\n        out = Dense(1, activation=\"linear\")(lstm_layer)\n        model = Model(inputs=inp, outputs=out)\n        model.compile(optimizer=\"adam\", loss=\"mse\")\n        es = EarlyStopping(monitor=\"loss\", patience=5, restore_best_weights=True)\n        model.fit(X, y, epochs=30, batch_size=32, callbacks=[es], verbose=0)\n\n        encoder = Model(inputs=inp, outputs=model.get_layer(\"encoder_lstm\").output)\n        embeddings = encoder.predict(X, verbose=0)\n        emb_df = pd.DataFrame(embeddings, index=df.index[seq_len:seq_len+len(embeddings)])\n        for i_col in range(emb_df.shape[1]):\n            df[f\"lstm_emb_{i_col}\"] = np.nan\n            df.loc[emb_df.index, f\"lstm_emb_{i_col}\"] = emb_df.iloc[:, i_col].values\n    else:\n        print(\"Not enough samples for LSTM embedding.\")\nelse:\n    print(\"‚ùå TensorFlow not available ‚Äî skipping LSTM embedding features.\")\n\n# ================================================================\n# 6Ô∏è‚É£ SAVE & DISPLAY FINAL FEATURE DATASET\n# ================================================================\nprint(f\"\\n‚úÖ Final engineered DataFrame shape: {df.shape}\")\nprint(f\"‚úÖ Total columns: {len(df.columns)}\")\nprint(df.head())\n\ndf.to_csv(\"final_engineered_df.csv\")\nprint(\"üíæ Saved as final_engineered_df.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T17:42:35.731367Z","iopub.execute_input":"2026-01-11T17:42:35.732170Z","iopub.status.idle":"2026-01-11T17:43:55.902579Z","shell.execute_reply.started":"2026-01-11T17:42:35.732138Z","shell.execute_reply":"2026-01-11T17:43:55.901803Z"}},"outputs":[{"name":"stdout","text":"Raw hourly data shape: (14816, 3)\n                         zone1      zone2      zone3\nDateTime                                            \n2022-09-14 17:00:00  60.082000  15.192000  60.328000\n2022-09-14 18:00:00  64.758333  16.280000  58.718333\n2022-09-14 19:00:00  66.251667  17.761667  54.316667\n2022-09-14 20:00:00  79.946667  24.691667  64.728333\n2022-09-14 21:00:00  86.553333  25.910000  70.788333\n‚úÖ After feature engineering: 70 columns\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/2474188632.py:56: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n  df[f\"{z}_pct_change_1\"] = df[z].pct_change(1).replace([np.inf,-np.inf], np.nan).fillna(0)\n/tmp/ipykernel_47/2474188632.py:56: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n  df[f\"{z}_pct_change_1\"] = df[z].pct_change(1).replace([np.inf,-np.inf], np.nan).fillna(0)\n/tmp/ipykernel_47/2474188632.py:56: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n  df[f\"{z}_pct_change_1\"] = df[z].pct_change(1).replace([np.inf,-np.inf], np.nan).fillna(0)\n","output_type":"stream"},{"name":"stdout","text":"üß≠ Prophet detected ‚Äî extracting daily components...\n","output_type":"stream"},{"name":"stderr","text":"17:42:36 - cmdstanpy - INFO - Chain [1] start processing\n17:42:36 - cmdstanpy - INFO - Chain [1] done processing\n/tmp/ipykernel_47/2474188632.py:115: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n  comp_hourly = comp.reindex(pd.date_range(comp.index.min(), comp.index.max(), freq=\"H\")).ffill()\n2026-01-11 17:42:38.434596: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768153358.647323      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768153358.700844      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"üî∂ TensorFlow available ‚Äî training LSTM encoder...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/2474188632.py:152: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df_train = df[feature_cols].fillna(method=\"ffill\").fillna(0)\nI0000 00:00:1768153374.216171      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\nI0000 00:00:1768153377.280773     149 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Final engineered DataFrame shape: (14816, 107)\n‚úÖ Total columns: 107\n                         zone1      zone2      zone3  hour  dayofweek  month  \\\nDateTime                                                                       \n2022-09-14 17:00:00  60.082000  15.192000  60.328000    17          2      9   \n2022-09-14 18:00:00  64.758333  16.280000  58.718333    18          2      9   \n2022-09-14 19:00:00  66.251667  17.761667  54.316667    19          2      9   \n2022-09-14 20:00:00  79.946667  24.691667  64.728333    20          2      9   \n2022-09-14 21:00:00  86.553333  25.910000  70.788333    21          2      9   \n\n                     is_weekend  hour_sin      hour_cos  zone1_lag_1  ...  \\\nDateTime                                                              ...   \n2022-09-14 17:00:00           0 -0.965926 -2.588190e-01          NaN  ...   \n2022-09-14 18:00:00           0 -1.000000 -1.836970e-16    60.082000  ...   \n2022-09-14 19:00:00           0 -0.965926  2.588190e-01    64.758333  ...   \n2022-09-14 20:00:00           0 -0.866025  5.000000e-01    66.251667  ...   \n2022-09-14 21:00:00           0 -0.707107  7.071068e-01    79.946667  ...   \n\n                     lstm_emb_22  lstm_emb_23  lstm_emb_24  lstm_emb_25  \\\nDateTime                                                                  \n2022-09-14 17:00:00          NaN          NaN          NaN          NaN   \n2022-09-14 18:00:00          NaN          NaN          NaN          NaN   \n2022-09-14 19:00:00          NaN          NaN          NaN          NaN   \n2022-09-14 20:00:00          NaN          NaN          NaN          NaN   \n2022-09-14 21:00:00          NaN          NaN          NaN          NaN   \n\n                     lstm_emb_26  lstm_emb_27  lstm_emb_28  lstm_emb_29  \\\nDateTime                                                                  \n2022-09-14 17:00:00          NaN          NaN          NaN          NaN   \n2022-09-14 18:00:00          NaN          NaN          NaN          NaN   \n2022-09-14 19:00:00          NaN          NaN          NaN          NaN   \n2022-09-14 20:00:00          NaN          NaN          NaN          NaN   \n2022-09-14 21:00:00          NaN          NaN          NaN          NaN   \n\n                     lstm_emb_30  lstm_emb_31  \nDateTime                                       \n2022-09-14 17:00:00          NaN          NaN  \n2022-09-14 18:00:00          NaN          NaN  \n2022-09-14 19:00:00          NaN          NaN  \n2022-09-14 20:00:00          NaN          NaN  \n2022-09-14 21:00:00          NaN          NaN  \n\n[5 rows x 107 columns]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"name":"stdout","text":"üíæ Saved as final_engineered_df.csv\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ================================================================\n# Robust Hybrid Feature Engineering + Visualization Pipeline\n# Prophet (Daily) + LSTM (Hourly) + Symbolic & Programmatic Features\n# ================================================================\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\n\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# Assume you already have:\n#  üîπ data ‚Üí original 10-min resolution dataframe\n#  üîπ data_hourly_mean ‚Üí hourly mean dataframe\n# Example: data_hourly_mean = data.resample('H').mean()\n\ndf_hourly = data_hourly_mean.copy()\ndf_hourly.index.name = \"DateTime\"\n\nprint(f\"Raw hourly data shape: {df_hourly.shape}\")\n\n# --- Plot 1: Original vs Hourly Aggregated ---\nplt.figure(figsize=(10, 4))\nfor c in df_hourly.columns[:2]:\n    plt.plot(df_hourly.index[:500], df_hourly[c].iloc[:500], label=c)\nplt.title(\"Sample Hourly Power Demand (First 500 Samples)\")\nplt.xlabel(\"Time\"); plt.ylabel(\"Power (kW)\")\nplt.legend(); plt.tight_layout()\nplt.savefig(\"plot_hourly_timeseries.png\", dpi=300)\nplt.close()\n\ndef add_time_features(df):\n    df = df.copy()\n    df[\"hour\"] = df.index.hour\n    df[\"dayofweek\"] = df.index.dayofweek\n    df[\"month\"] = df.index.month\n    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5,6]).astype(int)\n    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n    return df\n\ndef add_lag_and_rolling(df, zones, lags=[1,3,6,12,24], rolls=[3,6,12,24]):\n    df = df.copy()\n    for z in zones:\n        for l in lags:\n            df[f\"{z}_lag_{l}\"] = df[z].shift(l)\n        for w in rolls:\n            df[f\"{z}_roll_mean_{w}\"] = df[z].rolling(window=w, min_periods=1).mean()\n            df[f\"{z}_roll_std_{w}\"] = df[z].rolling(window=w, min_periods=1).std().fillna(0)\n    return df\n\ndef add_derivatives(df, zones):\n    df = df.copy()\n    for z in zones:\n        df[f\"{z}_diff_1\"] = df[z].diff(1)\n        df[f\"{z}_diff_2\"] = df[z].diff(2)\n        df[f\"{z}_pct_change_1\"] = df[z].pct_change(1).replace([np.inf,-np.inf], np.nan).fillna(0)\n    return df\n\ndef add_fourier_terms(df, period_hours=24, K=3):\n    df = df.copy()\n    t = np.arange(len(df))\n    for k in range(1, K+1):\n        df[f\"fourier_sin_{k}\"] = np.sin(2*np.pi*k*t/period_hours)\n        df[f\"fourier_cos_{k}\"] = np.cos(2*np.pi*k*t/period_hours)\n    return df\n\ndef add_symbolic_like_features(df, zones):\n    df = df.copy()\n    for z in zones:\n        df[f\"{z}_sym_sinlag3_logroll6\"] = np.sin(df[f\"{z}_lag_3\"].fillna(0)) * np.log1p(df[f\"{z}_roll_mean_6\"].fillna(0))\n        df[f\"{z}_sym_lag1_over_lag24\"] = df[f\"{z}_lag_1\"] / (df[f\"{z}_lag_24\"].replace(0, np.nan))\n        df[f\"{z}_sym_prod_diff1_diff2\"] = df[f\"{z}_diff_1\"].fillna(0) * df[f\"{z}_diff_2\"].fillna(0)\n    return df\n\n\nzones = [c for c in df_hourly.columns if c.startswith(\"zone\")]\ndf = df_hourly.copy()\ndf = add_time_features(df)\ndf = add_lag_and_rolling(df, zones)\ndf = add_derivatives(df, zones)\ndf = add_fourier_terms(df, period_hours=24, K=2)\ndf = add_symbolic_like_features(df, zones)\n\nprint(f\"‚úÖ After feature engineering: {df.shape[1]} columns\")\n\n# --- Plot 2: Rolling Mean Example ---\nplt.figure(figsize=(10, 4))\nzone_ex = zones[0]\nplt.plot(df_hourly.index[:200], df_hourly[zone_ex].iloc[:200], label=\"Original\")\nplt.plot(df_hourly.index[:200], df[f\"{zone_ex}_roll_mean_6\"].iloc[:200], label=\"Rolling Mean (6)\")\nplt.title(f\"Rolling Mean Feature Example - {zone_ex}\")\nplt.xlabel(\"Time\"); plt.ylabel(\"Power (kW)\")\nplt.legend(); plt.tight_layout()\nplt.savefig(\"plot_rolling_mean.png\", dpi=300)\nplt.close()\n\n# --- Plot 3: Fourier Components ---\nplt.figure(figsize=(6, 3))\nplt.plot(df.index[:200], df[\"fourier_sin_1\"].iloc[:200], label=\"sin(1)\")\nplt.plot(df.index[:200], df[\"fourier_cos_1\"].iloc[:200], label=\"cos(1)\")\nplt.title(\"Fourier Seasonal Components\")\nplt.legend(); plt.tight_layout()\nplt.savefig(\"plot_fourier_terms.png\", dpi=300)\nplt.close()\n\n# --- Plot 4: Symbolic Feature Relationship ---\nplt.figure(figsize=(6, 4))\nsns.scatterplot(x=df[f\"{zone_ex}_sym_sinlag3_logroll6\"], y=df[f\"{zone_ex}_sym_prod_diff1_diff2\"], s=10)\nplt.title(\"Symbolic Feature Interaction\")\nplt.xlabel(\"sinlag3_logroll6\"); plt.ylabel(\"prod_diff1_diff2\")\nplt.tight_layout(); plt.savefig(\"plot_symbolic_scatter.png\", dpi=300); plt.close()\n\ntry:\n    from prophet import Prophet\n    prophet_available = True\nexcept:\n    try:\n        from fbprophet import Prophet\n        prophet_available = True\n    except:\n        prophet_available = False\n\nif prophet_available:\n    daily = df_hourly.sum(axis=1).resample(\"D\").mean().reset_index()\n    daily.columns = [\"ds\", \"y\"]\n\n    m = Prophet(daily_seasonality=False, weekly_seasonality=True, yearly_seasonality=True)\n    m.fit(daily)\n    forecast = m.predict(m.make_future_dataframe(periods=0, freq=\"D\"))\n    comp = forecast[[\"ds\", \"trend\", \"weekly\", \"yearly\", \"yhat\"]].set_index(\"ds\")\n    comp[\"residual\"] = daily.set_index(\"ds\")[\"y\"] - comp[\"yhat\"]\n\n    comp_hourly = comp.reindex(pd.date_range(comp.index.min(), comp.index.max(), freq=\"H\")).ffill()\n    comp_hourly = comp_hourly.reindex(df.index, method=\"ffill\")\n    for col in comp_hourly.columns:\n        df[f\"prophet_{col}\"] = comp_hourly[col].values\n\n    # --- Plot 5: Prophet Components ---\n    fig, axs = plt.subplots(3, 1, figsize=(7, 6))\n    axs[0].plot(comp.index, comp[\"trend\"]); axs[0].set_title(\"Prophet Trend Component\")\n    axs[1].plot(comp.index, comp[\"weekly\"]); axs[1].set_title(\"Prophet Weekly Component\")\n    axs[2].plot(comp.index, comp[\"residual\"]); axs[2].set_title(\"Prophet Residuals\")\n    plt.tight_layout(); plt.savefig(\"plot_prophet_components.png\", dpi=300); plt.close()\n\n\ntry:\n    import tensorflow as tf\n    from tensorflow.keras.models import Model\n    from tensorflow.keras.layers import LSTM, Dense, Input\n    from tensorflow.keras.callbacks import EarlyStopping\n    tf_available = True\nexcept:\n    tf_available = False\n\nif tf_available:\n    feature_cols = [c for c in df.columns if not c.startswith(\"zone\")] + [f\"{z}_lag_1\" for z in zones]\n    feature_cols = [c for c in feature_cols if c in df.columns]\n    df_train = df[feature_cols].fillna(method=\"ffill\").fillna(0)\n    seq_len = 24\n\n    X, y = [], []\n    total = df_hourly.sum(axis=1)\n    for i in range(len(df_train)-seq_len):\n        X.append(df_train.iloc[i:i+seq_len].values)\n        y.append(total.iloc[i+seq_len])\n    X, y = np.array(X), np.array(y)\n\n    if len(X) > 0:\n        inp = Input(shape=(X.shape[1], X.shape[2]))\n        lstm_layer = LSTM(32, return_sequences=False, name=\"encoder_lstm\")(inp)\n        out = Dense(1, activation=\"linear\")(lstm_layer)\n        model = Model(inputs=inp, outputs=out)\n        model.compile(optimizer=\"adam\", loss=\"mse\")\n        es = EarlyStopping(monitor=\"loss\", patience=5, restore_best_weights=True)\n        model.fit(X, y, epochs=20, batch_size=32, callbacks=[es], verbose=0)\n\n        encoder = Model(inputs=inp, outputs=model.get_layer(\"encoder_lstm\").output)\n        embeddings = encoder.predict(X, verbose=0)\n\n        emb_df = pd.DataFrame(embeddings)\n        pca = PCA(n_components=2).fit_transform(embeddings)\n        plt.figure(figsize=(6, 4))\n        plt.scatter(pca[:, 0], pca[:, 1], s=8, c=\"royalblue\", alpha=0.6)\n        plt.title(\"LSTM Embedding Projection (PCA)\")\n        plt.tight_layout(); plt.savefig(\"plot_lstm_embeddings.png\", dpi=300); plt.close()\n\n\ncorr = df.corr(numeric_only=True)\nplt.figure(figsize=(10, 8))\nsns.heatmap(corr.iloc[:20, :20], cmap=\"coolwarm\", center=0)\nplt.title(\"Feature Correlation Matrix (Sample 20√ó20)\")\nplt.tight_layout(); plt.savefig(\"plot_feature_correlation.png\", dpi=300); plt.close()\n\ndf.to_csv(\"final_engineered_df.csv\")\nprint(f\"‚úÖ Final engineered dataset saved: {df.shape}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================================================\n# Optimized Residual Hybrid: Prophet (daily) + LSTM (hourly residuals)\n#    + Optuna Hyperparameter Tuning + 3 Robust Validations + Plots\n# ==============================================================\n\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport optuna\nimport tensorflow as tf\nimport shap\nfrom prophet import Prophet\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score, roc_auc_score\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport os\n\nwarnings.filterwarnings(\"ignore\")\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nsns.set_style('whitegrid')\n\n# -------------------- Reproducibility --------------------\ndef set_seed(seed=42):\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seed(42)\n\n# -------------------- Load Data --------------------\ndf_hourly = data_hourly_mean.copy()\ndf_daily = data_daily_mean.copy()\ndf_hourly.index = pd.to_datetime(df_hourly.index)\ndf_daily.index = pd.to_datetime(df_daily.index)\n\n# -------------------- Prophet Daily Forecast --------------------\nprophet_daily_predictions = pd.DataFrame(index=df_daily.index)\nresiduals_hourly = pd.DataFrame(index=df_hourly.index)\n\nfor zone in df_daily.columns:\n    print(f\"üîπ Training Prophet (daily) for {zone}\")\n    prophet_df = df_daily[[zone]].reset_index()\n    prophet_df.columns = [\"ds\", \"y\"]\n    prophet_df.dropna(inplace=True)\n    \n    m = Prophet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)\n    m.fit(prophet_df)\n    \n    future_daily = pd.DataFrame({\"ds\": pd.date_range(df_daily.index.min(), df_daily.index.max(), freq='D')})\n    forecast_daily = m.predict(future_daily)\n    prophet_daily_predictions[zone] = forecast_daily.set_index('ds')['yhat']\n    \n    # Upsample to hourly\n    prophet_hourly = prophet_daily_predictions[zone].reindex(df_hourly.index, method='ffill')\n    residuals_hourly[zone] = df_hourly[zone] - prophet_hourly\n\n# -------------------- Feature Engineering --------------------\ndef create_features(series, index, n_lags=8, window=6):\n    df_feat = pd.DataFrame(index=index)\n    for l in range(1, n_lags+1):\n        df_feat[f'lag_{l}'] = series.shift(l)\n    df_feat[f'roll_mean_{window}'] = series.rolling(window).mean()\n    df_feat[f'roll_std_{window}'] = series.rolling(window).std()\n    df_feat['hour'] = index.hour\n    df_feat['dow'] = index.dayofweek\n    df_feat['month'] = index.month\n    return df_feat.dropna()\n\n# -------------------- LSTM Model --------------------\ndef build_lstm(input_shape, p):\n    model = Sequential([\n        LSTM(p['units1'], activation='relu', return_sequences=True, input_shape=input_shape),\n        Dropout(p['dropout']),\n        LSTM(p['units2'], activation='relu'),\n        Dense(1, dtype='float32')\n    ])\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=p['lr']), loss='mse')\n    return model\n\n# -------------------- Optuna Objective --------------------\ndef optuna_objective(trial, X_train, y_train, X_val, y_val):\n    p = {\n        \"units1\": trial.suggest_int(\"units1\", 64, 128),\n        \"units2\": trial.suggest_int(\"units2\", 32, 64),\n        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.3),\n        \"lr\": trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True),\n        \"batch\": trial.suggest_categorical(\"batch\", [16, 32])\n    }\n    X_train_3d, X_val_3d = X_train[..., None], X_val[..., None]\n    model = build_lstm((X_train.shape[1], 1), p)\n    es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    model.fit(X_train_3d, y_train, validation_data=(X_val_3d, y_val),\n              epochs=50, batch_size=p['batch'], verbose=0, callbacks=[es])\n    pred = model.predict(X_val_3d, verbose=0).flatten()\n    return np.sqrt(mean_squared_error(y_val, pred))\n\n# -------------------- Robust Validations --------------------\ndef conformal_intervals(y_true, y_pred, alpha=0.05):\n    res = np.abs(y_true - y_pred)\n    q = np.quantile(res, 1-alpha)\n    lower, upper = y_pred - q, y_pred + q\n    coverage = np.mean((y_true >= lower) & (y_true <= upper))\n    width = np.mean(upper - lower)\n    return coverage, width, q, lower, upper\n\ndef shap_stability(model, X, feature_names, folds=3, sample=50):\n    tscv = TimeSeriesSplit(folds)\n    cors = []\n    for train_idx, test_idx in tscv.split(X):\n        X_bg = X[train_idx][:sample]\n        X_test = X[test_idx][:sample]\n        predict_fn = lambda x: model.predict(x[...,None], verbose=0).flatten()\n        explainer = shap.KernelExplainer(predict_fn, X_bg)\n        vals = explainer.shap_values(X_test)\n        shap_mean = np.mean(np.abs(vals), axis=0)\n        s = pd.Series(shap_mean, index=feature_names)\n        cors.append(s)\n    corr_vals = [cors[i].corr(cors[i+1], method='spearman') for i in range(len(cors)-1)]\n    return np.mean(corr_vals)\n\ndef adversarial_validation(X_train, X_val):\n    y = np.concatenate([np.zeros(len(X_train)), np.ones(len(X_val))])\n    X = np.vstack([X_train, X_val])\n    clf = GradientBoostingClassifier()\n    clf.fit(X, y)\n    preds = clf.predict_proba(X)[:,1]\n    auc = roc_auc_score(y, preds)\n    return auc\n\n# -------------------- Training & Evaluation --------------------\nresults = []\ntrain_ratio = 0.8\n\nfor zone in df_hourly.columns:\n    print(f\"\\n‚öôÔ∏è Zone: {zone}\")\n    feat = create_features(residuals_hourly[zone], df_hourly.index)\n    X, y = feat.values, residuals_hourly[zone].loc[feat.index].values\n    idx = feat.index\n    split = int(len(X)*train_ratio)\n    X_train, X_val = X[:split], X[split:]\n    y_train, y_val = y[:split], y[split:]\n    \n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_val = scaler.transform(X_val)\n    \n    # ---- Optuna search ----\n    study = optuna.create_study(direction='minimize')\n    study.optimize(lambda tr: optuna_objective(tr, X_train, y_train, X_val, y_val),\n                   n_trials=12, show_progress_bar=True)\n    best_p = study.best_params\n    print(\"‚úÖ Best Hyperparameters:\", best_p)\n    \n    # ---- Train final LSTM ----\n    model = build_lstm((X_train.shape[1],1), best_p)\n    es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n    model.fit(X_train[...,None], y_train, epochs=50, batch_size=best_p['batch'], verbose=0, callbacks=[es])\n    \n    # ---- Predictions & Hybrid Forecast ----\n    y_val_pred = model.predict(X_val[...,None], verbose=0).flatten()\n    prophet_val = prophet_daily_predictions[zone].reindex(idx, method='ffill')[split:]\n    hybrid_val = prophet_val.values + y_val_pred\n    y_true_val = df_hourly[zone].loc[idx[split:]].values\n    \n    # ---- Metrics ----\n    rmse = np.sqrt(mean_squared_error(y_true_val, hybrid_val))\n    r2 = r2_score(y_true_val, hybrid_val)\n    print(f\"RMSE={rmse:.3f}, R¬≤={r2:.3f}\")\n    \n    # ---- Robust Validations ----\n    cov, width, q, lower, upper = conformal_intervals(y_true_val, hybrid_val)\n    shap_idx = shap_stability(model, X_train, feat.columns)\n    adv_auc = adversarial_validation(X_train, X_val)\n    \n    results.append({\n        \"Zone\": zone, \"RMSE\": rmse, \"R2\": r2,\n        \"CPI_Coverage\": cov, \"CPI_Width\": width,\n        \"SHAP_Stability\": shap_idx, \"Adversarial_AUC\": adv_auc\n    })\n    \n    # ---- Plots ----\n    plt.figure(figsize=(12,5))\n    plt.plot(idx[split:], y_true_val, label='Actual', color='black')\n    plt.plot(idx[split:], prophet_val, label='Prophet', alpha=0.6)\n    plt.plot(idx[split:], hybrid_val, label='Hybrid', color='orange')\n    plt.fill_between(idx[split:], lower, upper, color='gray', alpha=0.2, label='CPI band')\n    plt.title(f\"{zone}: Actual vs Predicted (Hybrid)\")\n    plt.legend(); plt.show()\n    \n    plt.figure(figsize=(10,4))\n    sns.histplot(y_true_val - hybrid_val, bins=30, kde=True, color='red')\n    plt.title(f\"{zone}: Residual Distribution\")\n    plt.show()\n    \n    plt.figure(figsize=(8,4))\n    sns.kdeplot(np.abs(y_true_val - hybrid_val), fill=True)\n    plt.title(f\"{zone}: Error Density\")\n    plt.show()\n\n# -------------------- Summary --------------------\nres_df = pd.DataFrame(results)\nprint(\"\\n‚úÖ Final Results:\")\nprint(res_df.round(4))\n\nplt.figure(figsize=(10,5))\nsns.barplot(data=res_df.melt(id_vars=\"Zone\", value_vars=[\"R2\",\"CPI_Coverage\",\"SHAP_Stability\"]),\n            x=\"Zone\", y=\"value\", hue=\"variable\")\nplt.title(\"Validation Summary Across Zones\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}